# bayleaf-agents

FastAPI service that hosts **LLM agents** (ChatGPT-like, but under your control) and calls **Bayleaf** tools.
Provider-agnostic (OpenAI / mock / others), with Postgres for conversation history.

## Features

* ðŸ”Œ Pluggable LLM provider (`mock` for dev, `openai` ready)
* ðŸ§° Tool calls to Bayleaf REST (e.g., `patient_summary`, `list_medications`)
* ðŸ’¬ Persistent conversations (PostgreSQL + SQLAlchemy + Alembic)
* ðŸ§¾ Structured JSON logs (structlog)

## Quick start

### Local (Docker Compose)

```bash
cp .env.example .env   # set your envs (OPTIONAL for mock)
docker compose up --build
```

### Health

```bash
curl -sS http://localhost:8080/health | jq
```

### Chat (stateless)

```bash
curl -sS -X POST http://localhost:8080/chat \
  -H 'Content-Type: application/json' \
  -d '{
    "channel":"bayleaf_app",
    "patient_id":"uuid-demo",
    "message":"Tenho dor de cabeÃ§a desde ontem.",
    "locale":"pt-BR",
    "metadata":{}
  }' | jq
```

### Chat with conversation memory

```bash
curl -sS -X POST http://localhost:8080/chat \
  -H 'Content-Type: application/json' \
  -d '{
    "channel":"bayleaf_app",
    "patient_id":"uuid-demo",
    "conversation_id":"demo-1",
    "message":"Sim, tenho nÃ¡usea e sensibilidade Ã  luz."
  }' | jq
```

## API

* `GET /health` â†’ `{ status, env, provider }`
* `POST /chat` â†’ body:

  ```json
  {
    "channel": "bayleaf_app | whatsapp | partner",
    "patient_id": "string",
    "message": "string",
    "locale": "pt-BR",
    "metadata": {},
    "conversation_id": "optional string"
  }
  ```

  response (abridged):

  ```json
  { "reply": "...", "used_tools": [], "trace_id": "chat_xxx", "conversation_id": "demo-1" }
  ```

## Configuration

Environment variables (see `.env.example`):

```
APP_ENV=dev
HOST=0.0.0.0
PORT=8080
LLM_PROVIDER=mock          # mock | openai
OPENAI_API_KEY=            # if LLM_PROVIDER=openai
OPENAI_MODEL=gpt-4o
BAYLEAF_BASE_URL=https://bayleaf.nonnenmacher.tech
BAYLEAF_TOKEN=
DATABASE_URL=postgresql+psycopg://bayleaf:bayleaf@db:5432/bayleaf_agents
LOG_LEVEL=INFO
```

## Development

### Run locally (without Docker)

```bash
python -m venv .venv && source .venv/bin/activate
pip install -e .
uvicorn bayleaf_agents.app:create_app --factory --reload --port 8080
```

### Tests

```bash
pytest -q
```

## Database & Migrations

* Postgres runs via Docker Compose (`db` service).
* Alembic runs automatically on container start.
* Manual migration commands (if needed):

  ```bash
  alembic revision -m "desc"
  alembic upgrade head
  ```

## Switch LLM provider

* Dev/default: `LLM_PROVIDER=mock`
* OpenAI:

  ```
  LLM_PROVIDER=openai
  OPENAI_API_KEY=sk-...
  OPENAI_MODEL=gpt-4o
  ```

*(Provider adapters live under `src/bayleaf_agents/llm/`.)*